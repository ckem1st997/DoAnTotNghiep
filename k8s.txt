// dọn dẹp docker
Bạn đã gửi
docker buildx prune --all
Bạn đã gửi
docker builder prune --all


curl https://releases.rancher.com/install-docker/20.10.sh | sh

sudo apt-get update


curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
chmod +x ./kubectl
sudo mv ./kubectl /usr/local/bin/kubectl


curl https://baltocdn.com/helm/signing.asc | gpg --dearmor | sudo tee /usr/share/keyrings/helm.gpg > /dev/null
sudo apt-get install apt-transport-https --yes
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/helm.gpg] https://baltocdn.com/helm/stable/debian/ all main" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list
sudo apt-get update
sudo apt-get install helm


wget -q -O - https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh | TAG=v5.4.6 bash



//bo qua
kubectl -n cattle-system exec -it rancher-6757f6b675-rj42p -- /bin/bash
kubectl -n cattle-system exec -it rancher-6757f6b675-97vtb -- /bin/bash

kubectl -n cattle-system patch deployment rancher -p '{"spec": {"template": {"spec": {"containers": [{"name": "rancher", "ports": [{"containerPort": 8888, "protocol": "TCP"}]}]}}}}'
//


k3d cluster create testcluster


helm repo add rancher-stable https://releases.rancher.com/server-charts/stable
kubectl create namespace cattle-system

# If you have installed the CRDs manually instead of with the `--set installCRDs=true` option added to your Helm install command, you should upgrade your CRD resources before upgrading the Helm chart:
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.7.1/cert-manager.crds.yaml
# Add the Jetstack Helm repository
helm repo add jetstack https://charts.jetstack.io
# Update your local Helm chart repository cache
helm repo update
# Install the cert-manager Helm chart
helm install cert-manager jetstack/cert-manager \
  --namespace cert-manager \
  --create-namespace \
  --version v1.7.1





helm repo add rancher-stable https://releases.rancher.com/server-charts/stable


helm install rancher rancher-stable/rancher \
  --namespace cattle-system \
  --set hostname=rancher.my.org \
  --set bootstrapPassword=admin \
  --set replicas=2 \
  --set service.type=LoadBalancer

docker run -d --name=rancher-server --restart=unless-stopped -p 8383:8383 --privileged rancher/rancher:v2.4.18
kubectl -n cattle-system rollout status deploy/rancher
 docker logs b0766b829514 2>&1 | grep "Bootstrap Password:" ==> trả về password để vô setup
krCcESY7g3DL38Yr
 
helm upgrade rancher rancher-stable/rancher \
  --namespace cattle-system \
  --set hostname=http://103.77.173.200/




  Node-port: sẽ call thông chủ yếu trong mạng local, có thể dùng internal ip hoặc extenal



==//
cài k3s
curl -sfL https://get.k3s.io | K3S_KUBE_VERSION=v1.26.8 sh -

move sang kubectl
 scp root@ubuntu:/etc/rancher/k3s/k3s.yaml ~/.kube/config
//
cấu hình nhiều domain trên cùng một ip của máy chủ
khi người dùng truy cập vào domain nào thì dns sẽ phân giải ip và gửi yêu cầu đó tới ip của máy chủ được cấu hình gán vào domain
trong yêu cầu đó sẽ có tên host là domain mà người dùng truy cập 
trong cấu hình ingress resource, có mục cấu hình host là gì
ingress controller sẽ dựa vào cấu hình đó so sánh với host có trong yêu cầu gửi tới và ánh xạ, gửi yêu cầu đó tới service được setup

cài dashboard hạ tầng
https://learn.netdata.cloud/docs/installing/kubernetes
chú ý chọn clusterip 19999 rồi ingress như thường


git submodule add http://192.168.3.147:8181/hacom/share/hacom.sharedrefs Sharedrefs


version: '3.8'

services:
  postgres:
    image: postgres
    restart: always
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: abc@123
      POSTGRES_DB: dbjira
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - postgres_data_back-up:/var/lib/postgresql/data-backup

  redis:
    image: redis
    restart: always
    ports:
      - "6376:6379"
    command: ["redis-server", "--requirepass", "abc@123"]
    volumes:
      - redis_data:/data
      - redis_data_back-up:/data-backup

  pgadmin:
    image: dpage/pgadmin4
    restart: always
    ports:
      - "8383:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@example.com
      PGADMIN_DEFAULT_PASSWORD: admin
    depends_on:
      - postgres

  redisinsight:
    image: redislabs/redisinsight
    restart: always
    ports:
      - "8301:8001"
    depends_on:
      - redis

volumes:
  postgres_data:
  postgres_data_back-up:
  redis_data:
  redis_data_back-up:

==> ui cảu redis, nếu không có user thì có thể bỏ qua
version: '3'
services:
  rancher:
    image: rancher/rancher:v2.7.9
    ports:
      - "8333:80"
      - "8443:443"
    privileged: true
    volumes:
      - /opt/rancher:/var/lib/rancher
    environment:
      - CATTLE_SYSTEM_CATALOG=bundled
      #- SSL_CERT_PATH=/etc/rancher/ssl/myserver.crt
     # - SSL_KEY_PATH=/etc/rancher/ssl/myserver.key

==>jira
version: '3'

services:
  jira:
    image: teamatldocker/jira
    ports:
      - "8083:8080"
    volumes:
      - /path/to/jira/data:/var/atlassian/application-data/jira
    environment:
      - JVM_MINIMUM_MEMORY=1024m
      - JVM_MAXIMUM_MEMORY=2048m
      - ATL_PROXY_NAME=
      - ATL_PROXY_PORT=
      - ATL_PROXY_SCHEME=
      - ATL_TOMCAT_PORT=8083
      - DATABASE_URL=jdbc:postgresql://192.168.3.96:5432/dbjira
      - DATABASE_DRIVER=org.postgresql.Driver
      - DATABASE_USER=postgres
      - DATABASE_PASSWORD=abc@123
      - ATL_DB_TYPE=postgres
      - ATL_JDBC_URL=jdbc:postgresql://192.168.3.96:5432/dbjira
    networks:
      - jiranet


networks:
  jiranet:
    driver: bridge
==>tool ngon c2
version: '3.6'

services:
  jira:
    image: teamatldocker/jira
    ports:
      - "8083:8080"
    volumes:
      - /var/volumn/jira/data:/var/atlassian/application-data/jira
    environment:
      - JVM_MINIMUM_MEMORY=1024m
      - JVM_MAXIMUM_MEMORY=2048m
      - ATL_PROXY_NAME=
      - ATL_PROXY_PORT=
      - ATL_PROXY_SCHEME=
      - ATL_TOMCAT_PORT=8083
      - DATABASE_URL=jdbc:postgresql://192.168.3.162:5432/dbjira
      - DATABASE_DRIVER=org.postgresql.Driver
      - DATABASE_USER=postgres
      - DATABASE_PASSWORD=abc@123
      - ATL_DB_TYPE=postgres
      - ATL_JDBC_URL=jdbc:postgresql://192.168.3.162:5432/dbjira
    networks:
      - jiranet

  gitlab:
    image: gitlab/gitlab-ce
    ports:
      - "8929:8929"
      
    hostname: 'gitlab.example.com'
    restart: always
    volumes:
      - /var/volumn/gitlab/config:/etc/gitlab
      - /var/volumn/gitlab/logs:/var/log/gitlab
      - /var/volumn/gitlab/data:/var/opt/gitlab
      - /var/volumn/gitlab/backup:/var/opt/gitlab/backups
    environment:
      GITLAB_OMNIBUS_CONFIG: |
        external_url 'http://gitlab.example.com:8929'
        gitlab_rails['gitlab_shell_ssh_port'] = 22
        postgresql['enable'] = false
        gitlab_rails['db_adapter'] = "postgresql"
        gitlab_rails['db_encoding'] = "unicode"
        gitlab_rails['db_host'] = "192.168.3.162"  # Thay đổi địa chỉ IP cụ thể của PostgreSQL của bạn
        gitlab_rails['db_port'] = "5432"          # Thay đổi cổng PostgreSQL của bạn nếu cần
        gitlab_rails['db_database'] = "db-gitlab"    # Thay đổi tên cơ sở dữ liệu của bạn
        gitlab_rails['db_username'] = "postgres"  # Thay đổi tên người dùng PostgreSQL của bạn
        gitlab_rails['db_password'] = "abc@123"   # Thay đổi mật khẩu PostgreSQL của bạn
    networks:
      - jiranet

networks:
  jiranet:
    driver: bridge

cài git runner bằng lệnh apt...
vào setting ci/cd  runner new project... và làm theo hướng dẫn, chú ý cài đặt tags trong runner phải trùng với trong gitlab.yml

nano /home/gitlab-runner/.bash_logout  commen hoặc xóa file nếu lỗi chạy shell


==> để call http
{
  "insecure-registries": ["gitlab.mycompany.com:4567"]
}
/etc/docker/daemon.json
sudo systemctl status docker
sudo systemctl start docker
sudo systemctl restart docker

sudo lsof -i :8301
kill -9 1090569

05-12-2023
==>db

version: '3.8'

services:
  postgres:
    image: postgres
    restart: always
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: abc@123
      POSTGRES_DB: dbjira
      NODE_PG_FORCE_NATIVE: 1
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - postgres_data_back-up:/var/lib/postgresql/data-backup

  redis:
    image: redis
    restart: always
    ports:
      - "6379:6379"
    command: ["redis-server", "--requirepass", "abc@123"]
    volumes:
      - redis_data:/data
      - redis_data_back-up:/data-backup

  pgadmin:
    image: dpage/pgadmin4
    restart: always
    ports:
      - "8383:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@gmail.com
      PGADMIN_DEFAULT_PASSWORD: admin
    depends_on:
      - postgres

  redisinsight:
    image: redislabs/redisinsight
    restart: always
    ports:
      - "8384:8001"
    depends_on:
      - redis
  sql-server:
    image: mcr.microsoft.com/mssql/server:2022-latest
    environment:
      SA_PASSWORD: "abc@1234567890"
      ACCEPT_EULA: "Y"
    ports:
      - "1433:1433"
    user: root
    volumes:
      - sql-data:/var/opt/mssql/data

  elasticsearch:
    container_name: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.5
    volumes:
     - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      ES_JAVA_OPTS: "-Xmx256m -Xms256m"
      cluster.name: "docker-cluster"
      network.host: 0.0.0.0
      discovery.zen.minimum_master_nodes: 1
      discovery.type: single-node

volumes:
  postgres_data:
  sql-data:
  elasticsearch-data:
  postgres_data_back-up:
  redis_data:
  redis_data_back-up:

==>
/////////////////////elk

version: '2.2'
services:
  apm-server:
    image: docker.elastic.co/apm/apm-server:7.17.15
    depends_on:
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
    cap_add: ["CHOWN", "DAC_OVERRIDE", "SETGID", "SETUID"]
    cap_drop: ["ALL"]
    ports:
    - 8200:8200
    networks:
    - elastic
    command: >
       apm-server -e
         -E apm-server.rum.enabled=true
         -E setup.kibana.host=kibana:5601
         -E setup.template.settings.index.number_of_replicas=0
         -E apm-server.kibana.enabled=true
         -E apm-server.kibana.host=kibana:5601
         -E output.elasticsearch.hosts=["elasticsearch:9200"]
    healthcheck:
      interval: 10s
      retries: 12
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:8200/

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.15
    environment:
    - bootstrap.memory_lock=true
    - cluster.name=docker-cluster
    - cluster.routing.allocation.disk.threshold_enabled=false
    - discovery.type=single-node
    - ES_JAVA_OPTS=-XX:UseAVX=2 -Xms1g -Xmx1g
    ulimits:
      memlock:
        hard: -1
        soft: -1
    volumes:
    - esdata:/usr/share/elasticsearch/data
    ports:
    - 9200:9200
    networks:
    - elastic
    healthcheck:
      interval: 20s
      retries: 10
      test: curl -s http://localhost:9200/_cluster/health | grep -vq '"status":"red"'

  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.15
    depends_on:
      elasticsearch:
        condition: service_healthy
    environment:
      ELASTICSEARCH_URL: http://elasticsearch:9200
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    ports:
    - 5601:5601
    networks:
    - elastic
    healthcheck:
      interval: 10s
      retries: 20
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:5601/api/status

volumes:
  esdata:
    driver: local

networks:
  elastic:
    driver: bridge

/////////


version: '3.8'

services:
  postgres:
    image: postgres
    restart: always
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: abc@123
      POSTGRES_DB: dbjira
      NODE_PG_FORCE_NATIVE: 1
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - postgres_data_back-up:/var/lib/postgresql/data-backup

  redis:
    image: redis
    restart: always
    ports:
      - "6379:6379"
    command: ["redis-server", "--requirepass", "abc@123"]
    volumes:
      - redis_data:/data
      - redis_data_back-up:/data-backup

  pgadmin:
    image: dpage/pgadmin4
    restart: always
    ports:
      - "8383:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@gmail.com
      PGADMIN_DEFAULT_PASSWORD: admin
    depends_on:
      - postgres

  redisinsight:
    image: redislabs/redisinsight
    restart: always
    ports:
      - "8384:8001"
    depends_on:
      - redis
  sql-server:
    image: mcr.microsoft.com/mssql/server:2022-latest
    environment:
      SA_PASSWORD: "abc@1234567890"
      ACCEPT_EULA: "Y"
    ports:
      - "1433:1433"
    user: root
    volumes:
      - sql-data:/var/opt/mssql/data

  elasticsearch:
    container_name: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.5
    volumes:
     - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      ES_JAVA_OPTS: "-Xmx256m -Xms256m"
      cluster.name: "docker-cluster"
      network.host: 0.0.0.0
      discovery.zen.minimum_master_nodes: 1
      discovery.type: single-node
      cluster.routing.allocation.disk.threshold_enabled: false
    ulimits:
      memlock:
        hard: -1
        soft: -1
    healthcheck:
      interval: 20s
      retries: 10
      test: curl -s http://localhost:9200/_cluster/health | grep -vq '"status":"red"'
    networks:
    - elastic
    
  apm-server:
    image: docker.elastic.co/apm/apm-server:7.17.15
    depends_on:
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
    cap_add: ["CHOWN", "DAC_OVERRIDE", "SETGID", "SETUID"]
    cap_drop: ["ALL"]
    ports:
    - 8200:8200

    command: >
       apm-server -e
         -E apm-server.rum.enabled=true
         -E setup.kibana.host=kibana:5601
         -E setup.template.settings.index.number_of_replicas=0
         -E apm-server.kibana.enabled=true
         -E apm-server.kibana.host=kibana:5601
         -E output.elasticsearch.hosts=["elasticsearch:9200"]
    healthcheck:
      interval: 10s
      retries: 12
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:8200/
    networks:
    - elastic

    
  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.15
    depends_on:
      elasticsearch:
        condition: service_healthy
    environment:
      ELASTICSEARCH_URL: http://elasticsearch:9200
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    ports:
    - 5601:5601
    networks:
    - elastic
    healthcheck:
      interval: 10s
      retries: 20
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:5601/api/status

volumes:
  postgres_data:
  sql-data:
  elasticsearch-data:
  postgres_data_back-up:
  redis_data:
  redis_data_back-up:
networks:
  elastic:
    driver: bridge
///////////////////////////
version: '3.8'

services:
  postgres:
    image: postgres
    restart: always
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: abc@123
      POSTGRES_DB: dbjira
      NODE_PG_FORCE_NATIVE: 1
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - postgres_data_back-up:/var/lib/postgresql/data-backup

  redis:
    image: redis
    restart: always
    ports:
      - "6379:6379"
    command: ["redis-server", "--requirepass", "abc@123"]
    volumes:
      - redis_data:/data
      - redis_data_back-up:/data-backup

  pgadmin:
    image: dpage/pgadmin4
    restart: always
    ports:
      - "8383:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@gmail.com
      PGADMIN_DEFAULT_PASSWORD: admin
    depends_on:
      - postgres

  redisinsight:
    image: redislabs/redisinsight
    restart: always
    ports:
      - "8384:8001"
    depends_on:
      - redis
  sql-server:
    image: mcr.microsoft.com/mssql/server:2022-latest
    environment:
      SA_PASSWORD: "abc@1234567890"
      ACCEPT_EULA: "Y"
    ports:
      - "1433:1433"
    user: root
    volumes:
      - sql-data:/var/opt/mssql/data

  elasticsearch:
    container_name: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.5
    volumes:
     - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      ES_JAVA_OPTS: "-Xmx525m -Xms256m"
      cluster.name: "docker-cluster"
      network.host: 0.0.0.0
      discovery.zen.minimum_master_nodes: 1
      discovery.type: single-node
      cluster.routing.allocation.disk.threshold_enabled: false
   # ulimits:
     # memlock:
      #  hard: -1
     #   soft: -1
    healthcheck:
      interval: 20s
      retries: 10
      test: curl -s http://localhost:9200/_cluster/health | grep -vq '"status":"red"'
    networks:
    - elastic
    
  apm-server:
    restart: always
    image: docker.elastic.co/apm/apm-server:7.17.15
    depends_on:
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
    cap_add: ["CHOWN", "DAC_OVERRIDE", "SETGID", "SETUID"]
    cap_drop: ["ALL"]
    ports:
    - 8200:8200

    command: >
       apm-server -e
         -E apm-server.rum.enabled=true
         -E setup.kibana.host=kibana:5601
         -E setup.template.settings.index.number_of_replicas=0
         -E apm-server.kibana.enabled=true
         -E apm-server.kibana.host=kibana:5601
         -E output.elasticsearch.hosts=["elasticsearch:9200"]
    healthcheck:
      interval: 10s
      retries: 12
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:8200/
    networks:
    - elastic
  
  kibana:
    restart: always
    image: docker.elastic.co/kibana/kibana:7.17.15
    depends_on:
      elasticsearch:
       condition: service_healthy
    environment:
      ELASTICSEARCH_URL: http://elasticsearch:9200
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    ports:
    - 5601:5601
    networks:
    - elastic
    healthcheck:
      interval: 10s
      retries: 20
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:5601/api/status

  logstash:
    container_name: logstash
    restart: always
    image: docker.elastic.co/logstash/logstash:7.17.5
    depends_on:
      elasticsearch:
       condition: service_healthy
    volumes:
      - logstash-data:/usr/share/logstash
    command: >
       logstash-plugin install logstash-input-http
    ports:
      - "8686:8080"
      - 5044:5044
      - 9600:9600
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"     


volumes:
  postgres_data:
  sql-data:
  elasticsearch-data:
  postgres_data_back-up:
  redis_data:
  redis_data_back-up:
  logstash-data:
networks:
  elastic:
    driver: bridge
//////////////elk

version: '3.8'

services:
  elasticsearch:
    container_name: elasticsearch
    restart: always
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.5
    volumes:
      - es_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - elk
    environment:
      ES_JAVA_OPTS: "-Xmx512m -Xms256m"
      discovery.type: single-node
      cluster.name: "docker-cluster"
      network.host: 0.0.0.0
      discovery.zen.minimum_master_nodes: 1
      #ELASTIC_PASSWORD: abc@123

  logstash:
    container_name: logstash
    restart: unless-stopped
    image: docker.elastic.co/logstash/logstash:7.17.5
    
    command: >
      sh -c '
        logstash-plugin install logstash-input-http
      '
    volumes:
      - ./elk/logstash/config:/usr/share/logstash/config
      - ./elk/logstash/pipeline:/usr/share/logstash/pipeline
      - ./elk/logstash/data:/usr/share/logstash/data
      - ./elk/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./elk/logstash/pipeline:/usr/share/logstash/pipeline:ro
    ports:
      - "5044:5044"

      - "8080:8080"
    environment:
      LS_JAVA_OPTS: "-Xmx512m -Xms256m"
   #   network.host: 0.0.0.0
    #  path.config: "/usr/share/logstash/pipeline"
    networks:
      - elk
    depends_on:
      - elasticsearch

volumes:
  es_data:
networks:
  elk:
    driver: bridge
///////////////////

version: '3.8'

services:

  elasticsearch:
    container_name: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.5
    volumes:
     - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      ES_JAVA_OPTS: "-Xmx525m -Xms256m"
      cluster.name: "docker-cluster"
      network.host: 0.0.0.0
      discovery.zen.minimum_master_nodes: 1
      discovery.type: single-node
      cluster.routing.allocation.disk.threshold_enabled: false
    healthcheck:
      interval: 20s
      retries: 10
      test: curl -s http://localhost:9200/_cluster/health | grep -vq '"status":"red"'
    networks:
    - elastic
      
 
  apm-server:
    restart: always
    image: docker.elastic.co/apm/apm-server:7.17.5
    depends_on:
      elasticsearch:
        condition: service_healthy
    #  kibana:
      #  condition: service_healthy
    cap_add: ["CHOWN", "DAC_OVERRIDE", "SETGID", "SETUID"]
    cap_drop: ["ALL"]
    ports:
      - 8200:8200
    command: >
       apm-server -e
         -E apm-server.rum.enabled=true
         -E setup.kibana.host=kibana:5601
         -E setup.template.settings.index.number_of_replicas=0
         -E apm-server.kibana.enabled=true
         -E apm-server.kibana.host=kibana:5601
         -E output.elasticsearch.hosts=["elasticsearch:9200"]
    healthcheck:
      interval: 10s
      retries: 12
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:8200/
    networks:
    - elastic
  
  
  logstash:
    container_name: logstash
    restart: always
    image: docker.elastic.co/logstash/logstash:7.17.5
    depends_on:
      elasticsearch:
       condition: service_healthy
    volumes:
     # - logstash-data:/usr/share/logstash
      - ./elk/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./elk/logstash/pipeline:/usr/share/logstash/pipeline:ro
    command: >
       logstash-plugin install logstash-input-http
    ports:
      - "8686:8080"
      - "5045:5044"
      - "9600:9600"
    environment:
      LS_JAVA_OPTS: "-Xms512m -Xmx512m"
    networks:
     - elastic
       
  kibana:
    restart: always
    image: docker.elastic.co/kibana/kibana:7.17.5
    depends_on:
      elasticsearch:
         condition: service_healthy
    environment:
      ELASTICSEARCH_URL: http://elasticsearch:9200
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    ports:
      - 5601:5601
    networks:
      - elastic
    healthcheck:
      interval: 10s
      retries: 20
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:5601/api/status

volumes: 
  elasticsearch-data:
  logstash-data:
networks:
  elastic:
    driver: bridge

///////////
docker exec -it bf5620aa2c71 logstash-plugin install logstash-input-http

/// oracle
docker login container-registry.oracle.com
hopxc1997@gmail.com    
Aa
docker run -d --name oracle-db \
  -e DB_SID=ORCLCDB \
  -e DB_PDB=ORCLPDB1 \
  -e DB_CHARACTERSET=AL32UTF8 \
  -e DB_MEMORY=5GB \
  -e ORACLE_PWD=abc@123Hac0m \
  -p 1521:1521 \
  -p 5500:5500 \
  --network oracle-net \
  -v $(pwd)/data:/opt/oracle/oradata \
  -v data-oracle:/opt/oracle/oradata \
  container-registry.oracle.com/database/enterprise:19.3.0.0

docker exec -it oracle-db sqlplus -L sys/abc@123Hac0m//localhost:1521/ORCLCDB as sysdba @healthcheck.sql

